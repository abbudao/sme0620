\chapter{Principais Modelos Probabilísticos}
 \section{Modelos Discretos}
 \subsection{Distribuição Uniforme Discreta}
 A v.a.\ assume cada um de seus valores com igual probabilidade.

 Definição: A v.a.\ discreta $X$, assumindo valores $x_1,x_2,\dots,x_k$ tem 
 distribuição uniforme se, e somente se, sua f.m.p.\ é definida por: 
 \begin{align}
   p(x)=P(X=x)=\begin{cases}
     \frac{1}{k}, \text{\quad} x=x_1,x_2,\dots,x_k\\
     0, \text{\quad caso contrário}
   \end{cases}
 \end{align}
 Notação: $X \sim U_{d}(k)$
 A média e variância de x é:
 \begin{align}
   \mu_{x}=E(x)=\sum_{x \in R_{x}}x_i P(X=x_i)\\
   = \sum_{x \in R_{x}}x_i \frac{1}{k}= \frac{1}{k}\sum_{x_i \in R_{x}}\\
   \text{e}\\
   var(x)=E(X^2)-\{E(X)\}^2\\
   = \sum_{x_i \in R_{x}}(x_i -\mu_x )^2 p(X=x_i)\\
   =\frac{1}{k} \{\sum^k_{i=1} x_i^2 - \frac{(\sum_{i=1}^k)^2}{k}\}
 \end{align}
 Exemplo: Seja $x$ uma v.a.\ que indica o $n^o$ de pontos marcados na face 
 superior de um dado quando ele é lançado. Portanto, temos uma distribuição 
 uniforme discreta, cuja f.m.p.\ é dada por: 
 \begin{align}
   p(x)=P(X=x)-\begin{cases}
     \frac{1}{6},\text{\quad} x=1,2,3,4,5,6\\
     0, \text{\quad caso contrário}
   \end{cases}
 \end{align}
 E o $E(x)$ é: 
 \begin{align}
   \mu_{x}=E(x)=\frac{1}{6}(1+2+3+4+5+6)\\
   =\frac{1}{6}21= \frac{7}{2}=3,5
 \end{align}
 E a $var(x)$ é:
 \begin{align}
   E(x^2)=\frac{1}{6}(1^2 + 2^2 + \dots + 6^2)\\
   =\frac{91}{6}=15,17\\
   var(x)=\frac{91}{6}- \{\frac{7}{2}\}^2=\frac{105}{36}=2,92
 \end{align}
 \subsection{Distribuição Bernoulli}
 Considere uma v.a.\ $x$ que assume apenas dois valores 1, se ocorrer sucesso,
 0, se ocorrer fracasso. Indicaremos por ``p" a probabilidade de sucesso, Isto
 é, $P(\text{Sucesso})=P(x=1)=p$.
 Definição: A v.a.\ discreta $x$ que assume apenas valores 0 ou 1 tem Distribuição
 Bernoulli se, somente se, sua f.m.p.\ é definida por:
 \begin{align}
   p(x)=P(X=x)= \begin{cases}
     p^{x}(1-p){1-x}, \text{\quad} x=0,1, \text{\quad} 0<p<1\\
     0, \text{\quad caso contrário}
   \end{cases}
 \end{align}
 Notação: $X \sim Ber(p)$

 Exemplos: 
 $$p(x)=(\frac{2}{5})^x(1-\frac{2}{5})^x, \text{\quad}x=0,1$$\\
 $$p(x)=(\frac{7}{8})^{1-x}(1-\frac{7}{8})^{1-x}, \text{\quad }, x=0,1$$

 De forma similar, podemos apresentar $p(x)$ por:
 \begin{figure} 
   \centering
   \begin{tabular}{c c c}
     \toprule
     x&0&1\\ \midrule
     $P(X=x)$&$1-p$&$p$\\ \bottomrule
   \end{tabular}
   \label{fig:7}
 \end{figure}
 A média de $x$ é: 
 \begin{align}
   \mu_{x}=E(x)=p
 \end{align}
 e a variância de $x$ é: 
 \begin{align}
   \sigma^2 = var(x)=p (1-p)
 \end{align}
 Exemplo: Suponha o lançamento de um dado perfeito e o interesse é ocorrer a face
 3.
 \begin{align*}
   X=\begin{cases}
     1, \text{\quad se ocorrer a face }3\\
     0, \text{\quad caso contrário}\{1,2,4,5,6\}]
   \end{cases}
 \end{align*}
 Cuja f.m.p.\ é dada por:
 \begin{align}
   p(x)=P(X=x)=\begin{cases}
     \frac{1}{6}(1-\frac{1}{6})^{1-x}, \text{\quad}x=0,1\\
     0, \text{\quad caso contrário}
   \end{cases}
 \end{align}
 \begin{figure} 
   \centering
   \begin{tabular}{c c c}
     \toprule
     x&0&1\\ \midrule
     $P(X=x)$&$\frac{5}{6}$&$\frac{1}{6}$\\ \bottomrule
   \end{tabular}
   \label{fig:8}
 \end{figure}
 $X \sim Ber(\frac{1}{6})$
 A média de $x$ é: 
 \begin{align*}
   \mu_{x}=(X)=p=\frac{1}{6}
 \end{align*}
 e a variância de $x$ é: 
 \begin{align*}
   \sigma^2= var(x)=p(1-p)=\frac{1}{6}\frac{5}{6}=\frac{5}{36}
 \end{align*}
 \subsection{Distribuição Binominal}
 Considere $M$ ensaios de Bernoulli independentes, todos com a mesma probabilidade
 de sucesso $p$. A v.a.\ que conta o número de sucessos nos $M$ ensaios de Bernoulli
 é denominada v.a.\ binomial com parâmetro $M$ e $p$.

 \begin{description}
   \item{Definição}: A v.a.\ discreta $x$, correspondente ao $n^o$ de sucesso em $M$ ensaios
     independentes de Bernoulli, tem distribuição binomial se, e somente se, sua 
     f.m.p.\ é definida por: 
     \begin{align}
       p(x)=P(X=x)=\begin{cases}
         \binom{M}{x}p^x (1-p)^{M-x}, \text{\quad}x=0,1,\dots,M \text{\quad e }0<p<1\\
         0, \text{\quad caso contrário}
       \end{cases}
     \end{align}

   \item{Notação}:$ x \sim Bin(M,p)\\$
     Obs: $\binom{M}{x}=\frac{M!}{x!(M-x)!}$

     Temos que: 
     \begin{align}
       \mu_{x}=E(X)=Mp\text{a média de} x \text{e}\\
       \sigma^2 =var(x)=Mp(1-p), \text{a variância de x}
     \end{align}
   \item{Exemplo}: Considere uma linha de produção, onde 3 peças são selecionadas aleatoriamente
     e são classificadas como defeituosas (D) ou não-defeituosas(N). $X_{1},X_{2},X_{3}$
     são variáveis aleatórias que assumem $1$ se a peça for não-defeituosa e $0$ caso 
     contrário. A probabilidade da peça ser não-defeituosa é $p$ e , consequentemente, 
     a probabilidade da peça ser defeituosa é $1-p$. Estamos interessados na distribuição
     de:
     $$Y=X_{1}+X_{2}+X_{3}$$
     \begin{align*}
       x_1 = \begin{cases}
         1, \quad \text{se a peca e nao deituosa}\\
         0, \quad \text{se a peca e deituosa}
       \end{cases}
     \end{align*}
     \begin{tabular}{c c c c c c }
       \toprule
       & $X_1$  & $X_2$ & $X_3$   & $Y= X_1 +X_2+ X_3$ & $ P(Y=y)$\\ \midrule
       DNN &0 & 1 & 1 & 2 & $p^2(1-p)$\\\midrule

       DND& 0 & 1 & 0 & 1 & $p(1-p)^2$\\\midrule

       DDN& 0 & 0 & 1 & 1 & $p(1-p)^2$\\\midrule

       DDD&  0 & 0 & 0 & 0 & $(1-p)^3$\\\midrule

       NNN&   1 & 1 & 1 & 3 & $p^3$\\\midrule

       NND& 1 & 1 & 0 & 2 & $p^2(1-p)$\\\midrule

       NDN& 1 & 0 & 1 & 2 & $p^2(1-p)$\\\midrule

       NDD& 1 & 0 & 0 & 1 & $p(1-p)^2$ \\ \bottomrule

     \end{tabular}

     Abaixo estão os possíveis resultados do experimento:

     %Arvore zica aqui, pegar de algum colega

     \begin{figure} 
       \centering
       \begin{tabular}{c c c c c}
         \toprule
         y&0&1&2&3\\ \midrule
         $P(Y=y)$&$(1-p)^3$&$3p(1-p)^2$&$3p^2(1-p)$&$p^3$\\ \bottomrule
       \end{tabular}
       \label{fig:127}
     \end{figure}
      Ou seja,
      \begin{align*}
        p(y)=P(Y=y)=\begin{cases}
          \binom{3}{y}p^y (1-p)^{3-y}, \text{\quad}y=0,1,2,3\\
          0, \text{\quad caso contrário}
        \end{cases}
      \end{align*}
    \item{Exemplo}: Uma rede varejista compra certo tipo de equipamento eletrônico. O 
      fabricante indica que a taxa de quipamentos em perfeito estado é $97\%$.
      \begin{enumerate}[label=(\alph*)]
        \item Seleciona-se ao acaso 20 itens. Qual a probabilidade de haver pelo menos 
          um item defeituoso nesses 20?
        \item Seleciona-se aleatoriamente 20 itens em cada 10 carregamentos, qual a 
          probabilidade de haver 3 carregamentos com pelo menos um item defeituoso?
      \end{enumerate}
      $p$ taxa de equipamentos em perfeito estado\\
      $$p=0,97$$\\
      $y$: $n^o$ de equipamentos em perfeito estado.\\
      $$y \sim binom(20;0,97)$$\\

    \item{Resolucão:}
      \begin{enumerate}[label=(\alph*)]
        \item    $M=20$ itens\\
          p:Probabilidade de pelo menos um item defeituoso.\\
          $p=0,03$
          \begin{align*}
           X_i= \begin{cases}
             1, \quad \text{se o equipamente e defeituoso}\\
             0, \quad \text{c.c }
            \end{cases} 
          \end{align*}
          $$x \sim binom(20:0,03) \text{quad} x=1,2,3,4,5,\dots,20$$\\
          \begin{align*}
           Y=X_1 + X_2 + \ldots +X_20 
          \end{align*}
          \begin{align*}
            P(Y\ge 1)= 1-P(Y<1)\\
            =1-P(Y=0)
          \end{align*}
          \begin{align*}
            P(Y=0)= \binom{20}{0} (0,03)^0 (1-0,03)^{20-0}\\
            =0,5438
          \end{align*}
          \begin{align*}
            P(Y\ge 1)= 1-0,5438\\
            =0,4562
          \end{align*}
          Ou, resolvendo pela v.a.\ $Y$, temos:
\begin{align*}
           X_i= \begin{cases}
             1, \quad \text{Se o equipamento for perfeito} \\
             0, \quad \text{se o equipamente for defeituoso}
            \end{cases} 
          \end{align*}
          \begin{align*}
            P(Y\le 19)=1-P(Y>19)\\
            =1-P(Y=20)
          \end{align*}
          \begin{align*}
            P(y=20)=\binom{20}{20}0,97^{20}(1-0,97)^{20-20}\\
            =0,5438
          \end{align*}
          \begin{align*}
            P(y\le 19)=1-0,5339\\
            =0,4562
          \end{align*}
        \item 10 carregamentos: 20 itens são selecionados \\
          $Y$: $n^o$ de carregamento com pelo menos um item defeituoso \\
          $M=10$\\
          $Y=0,1,2,\ldots,10$\\
          $p:\quad \text{porporcao de ter pelo menos um item defeituoso em um carregamento}$\\
          $$p=0,4562$$\\
          $$Y \sim B(10:0,4562)$$\\
          \begin{align*}
            P(Y=3)=\binom{10}{3}(0,4562)^3 (1-0,4562)^{10-3}\\
            =0,1602
          \end{align*}
      \end{enumerate}
    \end{description}
     % \emph{Exercício}: Um fabricante adquire certo tipo de componente de um fornecedor.
     % Segundo este fornecedor, a proporção de componentes defeituoso é de 2\%. O fabricante
     % adquire 10 lotes por mês e de cada lote são selecionados 15 componentes para 
     % inspeção. Qual a probabilidade de que sejam encontrados 3 lotes com mais de um 
     % componente defeituoso?

      \subsection{Distribuição Geométrica}
      \begin{description}
        \item  Considere uma sequência de ensaios Bernoulli independentes em probabilidade de 
      sucesso $p$ ($0<p<1$). Seja a v.a.\ $x$ o $n^o$ de fracassos até a ocorrência 
      do $1^o$ sucesso. Similarmente, a v.a.\ $x$ pode ser vista como o $n^o$ de ensaios que precedem 
      o primeiro sucesso.

    \item{Definição}: A v.a.\ $x$ tem distribuição geométrica se, e somente se, sua 
      f.m.p.\ é definida por: 
      \begin{align}
        p_{x}(x)=P(X=x)=\begin{cases}
          p(1-p)^x, \quad x=0,1,2,\dots \quad 0<p<1\\
          0, \quad \text{caso contrário}
        \end{cases}
      \end{align}
      \begin{center}Notação: $X \sim Geo(p)$\end{center}
      Temos que:
      \begin{align}
        \mu_{x}=E(x)=\frac{1-p}{p} \text{\quad e a }\\
        \sigma^2 = var(x)=\frac{1-p}{p^2}
      \end{align}
      Similarmente, a variável aleatória $Y$ pode ser vista como o $n^o$ de ensaios que
      precedem o primeiro sucesso assim, $Y$ tem a distribuição geométrica com f.m.p.\ dada por:
        \begin{align}
        p_y(y)=P(Y>y)=\begin{cases}
          (1-p)^{y-1} \text{\quad }p,y=1,2,\dots \\
          0, \text{\quad Caso contrário}
        \end{cases}
      \end{align}
      Neste caso, a v.a.\ $Y$ pode ser vista como $Y=X+1$ e, consequentemente, o valor esperado de y eh:
      \begin{align} 
      mu_y=E(Y)=E(X+1)=E(X)=E(X)+1= \frac{1}{p}
    \end{align}
    E a variância de $Y$ e:
    \begin{align}
      \sigma_y^2=var(Y)=var(X+1)=var(X)= \frac{1-p}{p}^2
    \end{align}
  \item{Exemplo}: Um pesquisador está realizando um experimentos químicos independetes 
      e sabe que a probabilidade de que cada cada experimento apresnete uma reação 
      positiva é $0,3$. QUal é a probabilidade de que menos de 3 reações negativas 
      ocorram antes da primeira positiva?

      $x$:$n^o$ de ocorrência positiva 
      \begin{align*}
        x=&\begin{cases}
          1, \text{\quad se a reação positiva}\\
          0, \text{\quad caso contrário}
        \end{cases}
      \end{align*}
      $$P(x=1)=p=0,3$$\\
      $X: n^o$ de reações negativas até a ocorrência de uma positiva\\
      \begin{center}$Y \sim Geo(0,3)$\end{center}
      \begin{align*}
        P(X<3)=P(X=0)+P(X=1)+P(X=2)\\
        P(X=0)=(1-0,3)^0 \times 0,3 = 0,3\\
        P(X=1)=(1-0,3)^1 \times 0,3 = 0,21\\
        P(X=2)=(1-0,3)^2 \times 0,3 = 0,147\\
        P(X<3)=0,3+0,21+0147=0,657
      \end{align*}
      Ou ainda,
      \begin{align*}
        Y: n^o \quad \text{de ensaios até a ocorrência de reação positiva}\\
        R_y = \{ 1,2,3,\ldots \}\\
        P( Y<4 ) = P (Y \leq 3) = P(Y=1)+ P(Y=2)+P(Y=3)\\
        P(Y=y)= p(1-p)^{y-1} \quad y=1,2,\dots
      \end{align*}
     % Exercício: Pensar no exercício anterior com o $n^o$ de ensaios.
    \end{description}
      \subsection{Distribuição Binomial Negativa}
      \begin{description}
        \item  Considere ensaios independetes de Bernoulli ($p$) e definimos $X$ como o $n^o$ 
      de fracassos anteriores ao r-ésimos sucesso.

    \item{Definição}: A v.a.\ $x$ tem distribuição Binomial negativa se, e somente se,
      sua f.m.p.\ é definida por:
      \begin{align}
        p(x)=P(X=x)=&
        \begin{cases}
          \binom{x+r-1}{r-1} p^r (1-p)^x, \text{\quad x=0,1,2,\dots} \\
          0, \text{\quad caso contrário}
        \end{cases}
      \end{align}
    \begin{center}Notação: $X \mathtt{\sim}BN(r,p)$\end{center}
      Temos que: 
      \begin{align}
        \mu_{x}=E(x)=\frac{r(1-p)}{p} \\
        \sigma^2 = var(x)=\frac{1-p}{p^2}
      \end{align}
      Observações: 
      \begin{enumerate}
        \item Note que se $r=1$, temos o modelo geométrico.
        \item $$\binom{x+r-1}{r-1} = \binom{x+r-1}{x}$$
      \end{enumerate}
      A Binomial Negativa pode ser definida como o $n^o$ de ensaios necessários para 
      a obtenção do r-ésimo sucesso. Formando $y=x+r$ temos a quantidade desejada e 
      seus valores variam de $r$ em diante. Assim sendo $Y$ o $n^o$ de ensaios até 
      a obtenção de $r$ sucessos, temos: 
      \begin{align}
        p(y)=p(Y=y)=&\begin{cases}
          \binom{y-1}{m-1}p^m(1-p)^{y-m}, \text{\quad }y=m,m+1,\dots \\
          0, \text{\quad caso contrário}
        \end{cases}
      \end{align}
    \item{Exemplo}: Em uma serie do campeonato de basquete, o time que ganhar quatro em sete jogos sera
      o vencedor. Suponha que o time $A$ tenha probabilidade de $55\%$ de ganhar de $B$ e que $A$ e $B$ 
      se enfrentarao em uma serie de sete jogos. Qual a probabilidade de que $A$ venca a serie em 6 jogos?
     \begin{align*} 
       X:\text{O numero de derrotas de $A$ até que $A$ ganhe 4 partidas}\\
       X \mathtt{\sim}BN (r=4, p=0,55)
     \end{align*}
     \begin{align*}
       P(X=2)=\binom{2+4-1}{4-1} 0,55^{4}\times 0,45^{2}=0,1853
     \end{align*}
     Ou, de maniera similar, temos:
     \begin{align*}
       Y: \text{ numero de partidas até que $A$ venca o campeonato}
     \end{align*}
     \begin{align*}
       P(Y=6)= \binom{6-1}{4-1} 0,55^{4} \times 0,45^{6-4} = 0,1853
     \end{align*}
 \end{description}
 \subsection{Distribuição Hipergeometrica}
Considere um conjunto de $n$ objetos dos quais $m$ são do tipo $I$
e $(n-m) $ são do tipo $II$. Para um sorteio de $r$ objetos $(r<n)$, 
feitos ao acaso e sem repeticao, defina $X$ como o número de objetos do tipo
$I$ selecionados.
\begin{description}
  \item{Definição}: A v.a.\ $X$ tem distribuicao Hipergeometrica se sua f.m.p.\ eh dada
    por:
    \begin{align*}
      P_x(x)= P(X=x)= \frac{\binom{m}{xs} \binom{n-m}{r-x}}{\binom{n}{r}}
    \end{align*}
    Em que $x$ (inteiro) eh tal que:
    \begin{align*}
      max \{0,r-(n-m)\} \leq x \leq min \{ r,m \}
    \end{align*}
  \item{Observação}: Os limites de $x$ garantem que situaçoes absurdas ocorram.
  \item{Temos que: }
    \begin{align*}
      E(X) = r \frac{m}{n} \\
      Var(x)= \frac{r\times m (n-m)(n-r)}{n^2 (n-1)}
    \end{align*}
  \item{Notacao}: $X \mathtt{\sim} Hgeo (m,n,r)$
  \item{Exemplo}: Considere que em um lote de $20$ peças, existam $4$ defeituosas.
    Seleciona-se $5$ dessas peças, sem resposicao, qual seria a probabilidade 
    de duas defeituosas terem sido escolgidas?
    \begin{align*}
      X: \text{$N^{o}$  de peças defeituosas em $5$ retiradas }\\
      P(x=2)=\frac{\binom{4}{2} \binom{16}{3}}{\binom{20}{5}}\\
      R_{x}: \{ 0,1,2,3,4 \}
    \end{align*}
\end{description}
\subsection{Distribuicao de Poisson}
Eh largamente empregada quando se deseja contar o número de eventos de certo tipo
que ocorrem em um certo periodo de tempo ou superficie ou volume.
\begin{description}
\item{Definicao} Uma v.a.\ tem Distribuição Poisson com parâmetro $\lambda$, $\lambda >0$,se sua
  f.m.p.\ eh dada por:
 \begin{align}
   P_{x} (x)= P(X=x)= \frac{e^{-\lambda}\lambda{x}}{x!}, \quad x=0,1,2,\ldots
 \end{align} 
 \item{Notacao}: $X \mathtt{\sim} Poi(\lambda)$
 \item{Temos que}:
   \begin{align}
     E(X)= \lambda \\
     Var(x)= \lambda
   \end{align}
   \item{Exemplo}: Uma central telefonica recebe, em media, 5 chamadas por minuto.
     Supondo que a distribuição de Poisson seja adequada nessa situação, obtenha a 
     probabilidade de que a central receba no maximo 2 chamadas durante um intervalo
     de um minuto.
     \begin{align*}
       X: n^{o} \text{de chamadas recebidas em 1 minuto em uma central telefonica}
       \\
       E(X)=\lambda= \text{5 chamadas/minuto}\\
     \end{align*}
     \begin{align*}
       P(X \leq 2)= P(X=0)+ P(X=1)+P(X=2)
     \end{align*}
     \begin{align*}
       P(X=0) = \frac{e^{-5}5^0}{0!}= 0,0067\\
       P(X=1) = \frac{e^{-5}5^1}{1!}= 0,0334\\
       P(X=2) = \frac{e^{-5}5^2}{2!}= 0,0842
     \end{align*}
     Logo,
     \begin{align*}
       P(X \leq 2)= 0,0067+0,0334+0,0842=0,1243
     \end{align*}
   \end{description}
     \subsubsection{O processo de Poisson}
     
     Suponha que $\mu$ seja a média de ocorrência do evento de interesse
     em $t$ unidades de medida(por exemplo, tempo). Denotamos por $\lambda$,
     a taxa média de ocorrência em uma unidade de medida, como $\mu= \lambda t$.
     Podemos reescrever a f.m.p.\ por:
     \begin{align*}
       p_{x} =P(X=x)= \frac{e^{-\lambda t} \left( \lambda t \right)^{x}}{x!}, \quad x=0,1,2,\ldots
     \end{align*}
     \begin{description} 
       \item{Exemplo}: Considere o exemplo anterior e calcule a probabilidade de que a central 
         telefonica receba no maximo duas chamadas em 4 minutos.
         \begin{align*}
           P(X \leq 2 \/ t=4) = P(X=0)+P(X=1)+P(X=2)
         \end{align*}
     \begin{align*}
       P(X=0) = \frac{e^{-5 \times 4}(5\times 4)^0}{0!}= 2,06 \times 10^{-9}\\
       P(X=1) = \frac{e^{-5 \times 4}(5\times 4)^1}{1!}= 4,12 \times 10^{-8}\\
       P(X=2) = \frac{e^{-5 \times 4}(5\times 4)^2}{2!}= 4,12 \times 10^{-7} 
     \end{align*}
    \begin{align*}
      P(X \leq 2 \/ t=4)= 2,06 \times 10^{-9}+4,12 \times 10^{-8}+4,12 \times 10^{-7} = 4,56 \times 10^{-7} \approx 0
    \end{align*} 
  \item{Resultados Imporatantes}
    \begin{description}
  \item {Resultado 1}: Se $X_1, X_2,\ldots, X_n$ sao independetes e $X_i \mathtt{\sim} Poisson(\lambda_i)$, então:
    \begin{align}
      Y= X_1+X_2+\ldots+X_n \mathtt{\sim} Poisson\left( \lambda_1+\ldots+\lambda_n \right)
    \end{align}
  \item {Resultado 2}: Se $X \mathtt{\sim}Bin(M,P)$. com $m$ grande e $P$ pequeno, pode-se aproximar a distribuição de 
    $X$ pela distribuição de Poisson, cujo parâmetro sera $\lambda = M \times P$.
    \begin{description}
      \item {Exemplo}: Numero de gols marcados em $M=100$ tentativas.

    \begin{align*}
      P=0,05 \quad \talque \quad  X \mathtt{\sim} Bin(100, 0,05) \\
      P(X \ge 50)=P(X=50), \ldots + P(X=100)= 1- \{P(X=0)+\ldots+P(X=49) \}\\
      E(X)=M \times p = \mu\\
      X \mathtt{\sim}Poi(\lambda= M \times P)
    \end{align*}

  \item{Exercício}: Em certa instalacao industrial, acidentes ocorrem com baixa frequência. Sabe-se que 
    a probabilidade de um acidente ocorrer em um certo dia eh $0,005$ e que os acidentes são independentes.
    
    \begin{enumerate}[label=(\alph*)]
      \item Qual a probabilidade de que em um periodo de 400 dias haja no maximo 3 dias com acidente?
      Utilize a aproximacao pela distribuição de Poisson.
    \item Calcule a probabilidade exata do item anterior e compare os resultados.
   \end{enumerate}
  \end{description}
\end{description}
   \end{description}
   \section{Modelos Continuos}
   \subsection{Distribuicao Uniforme} 
   \begin{description}
     \item {Definição}: Uma v.a.\ contínua $X$ tem distribuição uniforme no intervalo $(a,b), \quad a,b \in \mathbb{R}$,
       se sua f.d.p.\ eh dada por:
\begin{align}
  f_x(x) = \begin{cases}
\frac{1}{b-a}, \quad a \leq x \leq b  \\
   0, \quad \text{caso contrário}
  \end{cases}
\end{align}
\item{Notação}: $X \mathtt{\sim} U(a,b)$
\item A f.d.a.\ eh dada por:
  \begin{align}
    F_x{x} = \begin{cases}
      0, \quad \text{se} x<a \\
      \frac{x-a}{b-a}, \quad \text{se} a\leq<b\\
      1, x \ge b
    \end{cases}
  \end{align}
  \begin{align}
    P(X \leq x) = \int_{- \infty}^{x} f_{x} (t) dt = \int_{a}^{x} \frac{1}{b-a} dt\\
    \nonumber = \frac{1}{b-a}t |_{a}^{x} = \frac{x^a -a}{b-a}
  \end{align}
\item{Exemplo}:
  \begin{align*}
    P(a_1 \leq X \leq b_1) = F_{x} (b_1) - F_{x}(a_1) \\
    P(X > a_1)= 1- P(X \leq a_1) \\
    = 1-F_{x} (a_1) \\
    P(X \eq a_1)= F_{x}(a_1)
  \end{align*}
 \item A media de $x$ eh:
   \begin{align*}
     E(X) = \frac{a+b}{2}
   \end{align*}
 \item E a variância de $x$ eh:
   \begin{align*}
     Var(x) = \frac{ \left(b-a\right)^2 }{12}
   \end{align*}
   \item{Exemplo}: Seja $X$ uma v.a.\ com distribuição uniforme, $U(-1/2 , 1/2). $
     Calcule:
\begin{enumerate}[label=(\alph*)]
  \item $F_{x} (x)$
  \item $P(\frac{-1}{4} \leq x \leq \frac{1}{4})$
  \item $E(x)$ e $Var(x)$
\end{enumerate}
Sabe-se que:
\begin{align*}
  X \mathtt{\sim}  U(\frac{-1}{2}; \frac{1}{2})
\end{align*}
Assim, a f.d.p.\ de $x$ eh:
\begin{align*}
  f_{x} (x)= \frac{1}{\frac{1}{2}- \left( \frac{-1}{2}\right)} = 1 \quad \frac{-1}{2}<x<\frac{1}{2}
\end{align*}
\begin{enumerate}[label=(\alph*)]
  \item  $F_{x}(x)=?$
    \begin{align*}
      F_{x} (x)= P(X \leq x) = \int_{ -\infty  }^{x} f(t)dt\\
      = \int_{\frac{-1}{2}}^{x} 1 dt= t|_{\frac{-1}{2}}{x} \\
      = x+ \frac{1}{2}
    \end{align*}
    \begin{align*}
      F_{x} (x) = P(X \leq x) = \begin{cases}
        0, \quad \text{se}  x< \frac{-1}{2} \\
        x+ \frac{1}{2} , \quad \text{se} \frac{-1}{2} \leq x < \frac{1}{2} \\
        1, \quad x \ge \frac{1}{2}
      \end{cases}
    \end{align*}
    \item 
      \begin{align*}
      P(\frac{-1}{4}\leq X \leq \frac{1}{4})  = \int_{\frac{-1}{4}}^{\frac{1}{4}}\\
      = x|_{\frac{-1}{4}}^{\frac{1}{4}}= \frac{1}{4}+\frac{1}{4}=\frac{1}{2}
    \end{align*}
    Ou 
    \begin{align*}
      P(\frac{-1}{4} \leq X \leq \frac{1}{4})= F_{x}(\frac{1}{4})-F_{x}(\frac{-1}{4}) \\
      \frac{3}{4}- \frac{1}{4}= \frac{1}{2}
    \end{align*}
    \item 
      \begin{align*}
        E(X) = \frac{a+b}{2} \\
        = \frac{\frac{-1}{2} + \frac{1}{2}}{2}=0\\
        Var(x)= \frac{ \left( b-a \right)^2 }{12}= \frac{ \left( \frac{1}{2} + \frac{1}{2} \right)^2 }{12}= \frac{1}{12}
      \end{align*}
\end{enumerate}

   \end{description}
\subsection{Distribuição Exponencial}
\begin{description}
  \item {Definição}: Uma v.a.\ contínua $X$ tem distribuição exponencial com parâmetro $\lambda, \lambda>0$, se sua
    f.d.p.\ eh dada por:
    \begin{align*}
      f_{x} (x)= \begin{cases}
        \lambda e^{- \lambda x} , \quad x \ge 0 \\
        0, \quad \text{caso contrário}
      \end{cases}
    \end{align*}
  \item{Notação}: $X \mathtt{\sim} Exp(\lambda)$
    \item A f.d.a.\ de $x$ eh:
      \begin{align*}
        P(X \le x)  = \int_{ -\infty }{x} f_{x}(t)dt \\
        = \int_{0}^{x} \lambda e^{-\lambda t } dt \\
        = -e^{-\lambda t} |_{0}^{x} = -e^{-\lambda x} +1\\
        = 1- e^{-\lambda x}
      \end{align*}
      \begin{align*}
        F_{x} (x) = \begin{cases}
         0, \quad x<0\\
         1-e^{-\lambda x} , x\ge 0
        \end{cases}
      \end{align*}
    \item A media e variancia de x sao:
      \begin{align*}
        E(x) = \frac{1}{\lambda}
      \end{align*}
      \begin{align*}
        Var(x) = \frac{1}{\lambda^2}
      \end{align*}
    \item{Propriedade}:
      \begin{enumerate}
        \item Se $X \mathtt{\sim}  Exp(\lambda)$, então:
        \begin{align*}
          P(X> a+b  \/ x>b) = P(X > a)
        \end{align*}
        Esta propriedade eh conhecida por falta de memoria e eh a unica distribuição 
        contínua que tem essa propriedade.

        Observação: Outra parametrizacao para a distribuicao exponencial eh:
        \begin{align*}
          f_{x} (x)= \frac{1}{2}e^{-\frac{x}{2}}, \quad x\ge 0
        \end{align*}
        Ou seja, $\lambda= \frac{1}{\alpha}$
        A media de x sera:
        \begin{align*}
          E(x)  = \alpha
        \end{align*}
        E a variância eh dada por:
        \begin{align*}
          Var(x) = \alpha^2
        \end{align*}
        Exemplo: Seja $X$ o tempo de vida util de um fusivel que tem distribuicao Exponencial
        com vida media de 100 horas. Qual a probabilidade de um fusivel durar mais de 150
        horas?
        \begin{align*}
          X \sim  Exp(\frac{1}{100}) \\
          \mu = E(x)= \frac{1}{\lambda}=100 \left( \lambda= \frac{1}{100} \right)\\
          P(X> 150)= int_{150}^{\infty} \frac{1}{100} e^{- \frac{1}{100} x} dx \\
          =0,22313
        \end{align*}
        Ou 
        \begin{align*}
          P(X>150) = 1- P(X \le 150)= 1- \int_{0}^{150} \frac{1}{100} e^{- \frac{1}{100}x}dx \\
          = 0,22313
        \end{align*}
      \end{enumerate}
\end{description}
\subsection{Distribuição Normal}
E a distribuicao mais importante dos modelos probabilisticos. 
Eh tambem conhecida como distribuicao gaussiana. Sua representação 
gráfica eh conhecida por curva em forma de sino.
\begin{description}
  \item {Definição:}  Uma v.a.\ contínua $X$ tem Distribuição normal com parâmetro $\mu$ (media) e 
    $\sigma^2$ se sua f.d.p.\ eh dada por:
    \begin{align}
      f_{x} (X)= \frac{1}{\sqrt{2\pi \sigma^2}} e^{\frac{-1}{2\sigma^2} \left( x-\mu \right)^2} \quad -\infty<x<\infty \\
      \text{Com } \quad -\infty < \mu < \infty, \quad \sigma^2>0
    \end{align}
  \item {Notação:} $X \sim N(\mu ; \sigma^2)$

Uma ilustração gráfica da sua f.d.p.\ eh:
%Grafico aqui
A media e variância de $x$ sao:
\begin{align*}
E(x) =\mu \\
Var(x)=\sigma^2
\end{align*}
\item {Propriedades:}
A distribuição eh simetrica em relacao `a media. Isto eh,
\begin{align}
  f(\mu - x) = f(\mu+x), \quad \forall x \in \mathbb{R}
\end{align}
\item Como a area total sob a curva eh igual a 1, `a esquerda e `a direita de $\mu$, 
  a area eh igual a $0,5$.
\item 
  \begin{align*}
    P(\mu -\sigma \leq X \leq \mu+\sigma)= 0,6896\\
    P(\mu -2\sigma \leq X \leq \mu+2\sigma)= 0,9546\\
    P(\mu -3\sigma \leq X \leq \mu+3\sigma)= 0,9973
  \end{align*}
Ilustrando:
%Grafico aqui
%http://johncanning.net/wp/?p=1202

A f.d.a.\ de uma v.a.\ $X \sim N(\mu,\sigma^2)$ eh:
\begin{align*}
  F_{x} (X)= P(X \leq x)= \int^{x}_{-\infty} \frac{1}{\sqrt{2\pi \sigma^2}}e^{\frac{-1}{2\sigma^2} \left( t- \mu \right)^2} dt 
\end{align*}
Cuja integral nao tem solucao analitica. Assim, calculamos suas probabilidades com auxilio de tabelas.

\item {Definição}: Se $X \sim N(\mu; \sigma^2)$, entao a v.a.\ $Z$ eh definida por:
  \begin{align}
   Z= \frac{X-\mu}{\sigma} 
  \end{align}
  Tera a distribuição normal com media 0 e variância 1. Ou seja, $Z \sim N(0,1)$.
  
  Essa distribuição eh conhecida como distribuição normal-padrão ou reduzida. 
\end{description}
  \subsubsection{Calculo de probabilidades}
  \begin{description}
    \item {Exemplo} Uso da tabela normal padrão:

      Seja $Z\sim N(0,1)$ calcule:
      \begin{enumerate}
        \item $P(0 \leq Z \leq 1,65)$
        \item $P(Z \leq 0,5)$
        \item $P(Z < -1,57)$
        \item $P(-0,65 \leq Z \leq 0,5)$
        \item $P(0,8 \leq Z < 1,4)$
        \item $P(0 \leq Z \leq z)=0,4753$
        \item $P(Z < z)=0,05$
      \end{enumerate}
      
      Resolva:
      \begin{enumerate}
        \item $P(0 \leq Z \leq 1,65)$
          % grafico aqui
          %Olhando a primeira tabela:
        \begin{align*}          P(0 \leq Z \leq 1,65)= 0,45053 \end{align*}
          %Olhando a segunda tabela:
          Ou:
          \begin{align*}
          P(0 \leq Z \leq 1,65)= P(Z < 1,65)-P(Z \leq 0) \\
          = P(z < 1,65)- 0,5 \\
          = 0,9505 - 0,5 = 0,4505
        \end{align*}
      \item $P(Z < 0,5)$
%grafico aqui
        \begin{align*}
          P(Z < 0,5)= 0,5 + P(0 \leq Z \leq 0,5) \\
          = 0,5 + 0,19146 \\
          = 0,69146
      \end{align*}
      Ou 
      \begin{align*}
        P(Z <0,5) = 0,6915
      \end{align*}

    \item $ P(Z< -1,57)$
      %grafico aqui
      \begin{align*}
        P(Z< -1,57) = P(Z> 1,57)\\
        =0,5 - P(0 \leq Z \leq 1,57) \\
        = 0,5 - 0,44179 \\
        = 0,0582
      \end{align*}
      Ou 
      \begin{align*}
        P(Z < -1,57) = 0,0582
      \end{align*}
    \item $P(-0,65 \leq Z \leq 0,65)$
      %Grafico aqui
      \begin{align*}
        P(-0,65 \leq Z \leq 0) = P(-0,65 \leq Z \leq 0) \\
        =2 P(0 \leq Z \leq 0,65) \\
        =2 \times 0,24215 \\
        =0,4843
      \end{align*}
      \begin{align*}
        P( -0,65 \leq Z \leq -0,65 ) = P(Z < 0,65) - P(Z < -0,65)
      \end{align*}
    \item 
      %grafico aqui
      \begin{align*}
        P(0,8 < z < 1,4)  = P(0 \leq Z \leq 1,4) - P(0 \leq Z \leq 0,8) \\
        = 0,41924 - 0,28814
      \end{align*}
    \item $P(0 \leq Z \leq z) = 0,4753$
      %grafico aqui
      \begin{align*}
       z= 1,965 
      \end{align*}
    \item $P(Z < z) = 0,05$
      %Grafico aqui
      \begin{align*}
       z= -1,645 
      \end{align*}
      \end{enumerate}

    \item {Exemplo:} Seja $X \sim N(90,100)$ \\
      \begin{description}
        \item  {Determine:}
      \begin{enumerate}[label=(\alph*)]
        \item $P(80 < x < 100)$
        \item $P(x \geq  90)$
        \item $P(60 \leq x \leq 75 )$
      \end{enumerate}

    \item {Resolucão:}
      \begin{enumerate}[label=(\alph*)]
        \item $P(80 < x < 100)$
          %grafico aqui
          \begin{align*}
            Z= \frac{X-\mu  }{\sigma} \\
            z_1 = \frac{80-90}{10}=-1\\
            z_2 = \frac{100-90}{10}=1
          \end{align*}
         \begin{align*}
           P(80<X < 100) = P(-1 < Z <1)
         \end{align*} 
            %Grafico aqui
         \begin{align*}
           P(-1 < Z < 1)  = 2 \times P(0<Z < 1) \\
           = 2 \times 0,34134 \\
           =0,6826
         \end{align*}

        \item $P(x \geq  90)$
          %grafico aqui
          \begin{align*}
            P(x \geq 90) =P(Z \geq \frac{90-90}{10}) \\
            = P(Z \geq 0)=0,5
          \end{align*}

        \item $P(60 \leq x \leq 75 )$
          %grafico aqui
          \begin{align*}
            P(60 \leq X \leq 75 ) \\
            =P(\frac{60-90}{10} \leq Z \leq \frac{75-90}{10}) \\
            =P(-3 \leq Z \leq 1,5)
          \end{align*}
          %Grafico aqui
          \begin{align*}
            P(-3 < Z < -1,5)\\
            =P(Z <1,5)- P(Z< -3) \\
            =0,0668- 0,0013 \\
            =0,0655
          \end{align*}

      \end{enumerate}
    \item {Exemplo:} Seja $X \sim \mathtt{N}(50; 10^2)$
      \begin{description}
        \item {Determine:}
          \begin{enumerate}[label=(\alph*)]
   \item $P(|X-50| <10)$
  \item $P( \mu-a \leq X \leq \mu +a )=0,9$
  \item $P(K< X <70)=0,8185$
  \item $P(K < x <75)= 0,3031$
          \end{enumerate}
        \item {Resolucao:}
\begin{enumerate}[label=(\alph*)]
   \item $P(|X-50| <10)$
     \begin{align*}
       \begin{cases}
        X-50<10 \Rightarrow X<60 \\
        -(X-50) <10 \Rightarrow X>40
       \end{cases}
     \end{align*}
     \begin{align*}
       P(|X-50| <10)  = P(40<X<60) \\
   = P(\frac{40-50}{10}< Z < \frac{60-50}{10}) \\
   = P(-1 < Z < 1)
 \end{align*} 
 %grafico aqui
\begin{align*}
  P(-1 < Z <1)  = 2 \times P(0 < Z <1) \\
  = 2 \times 0,34124 \\
  \simeq 0,68
\end{align*}

  \item $P( \mu-a \leq X \leq \mu +a )=0,9$
\begin{align*}
  P(50- a \leq X \leq 50 +a)  = 0,9 \\
  P(\frac{(50-a)-50}{10}) \leq Z \leq \frac{(50+a)-50}{10} \\
  P(\frac{-a}{10} \leq Z \leq \frac{a}{10})=0,9 
\end{align*}
%grafico aqui
\begin{align*}
  P( \frac{-a}{10} \leq Z \leq \frac{a}{10} ) = 2 \times P(0 \leq Z \leq \frac{9}{10})= 0,9 \\
  P(0 \leq Z \leq \frac{a}{10})=0,45 \\
  \frac{a}{10}= 1,645 \\
  a = 16,5
\end{align*}
  \item $P(K< X <70)=0,8185$
    %grafico aqui
    \begin{align*}
      P( \frac{K-50}{10} < Z < \frac{70-50}{10} ) = 0,8185 \\
      P(\frac{K-50}{10} < Z < 2) =0,8185
    \end{align*}
    %grafico aqui
    \begin{align*}
      P( \frac{K-50}{10}<Z<2 )  = 0,8185 \\
      P( \frac{K-50}{10} < Z <0) + P(0 < Z <2) =0,8185 \\
      P(\frac{K-50}{10}<Z < 0) = 0,8185 - 0,47725 \\
      P( \frac{K-50}{10} < Z < 0 ) =0,3413
    \end{align*}
    %grafico aqui
    \begin{align*}
      \frac{-(K-50)}{10} = 10 \\
      K= 40
    \end{align*}
  \item $P(K < x <75)= 0,3031$
    %grafico aqui
    Temos o caso do Grafico 1 caso $P(50 < X < 75) > 0,3031$. Do contrário, se 
    $P(50 < X < 75) < 0,3031$, temos o caso do Grafico 2.
    \begin{align*}
      P(50 < X < 75)  \\
      =P(\frac{50-50}{10} < Z < \frac{75-50}{10}) \\
      =P(0 < Z < 2,5) = 0,49379
    \end{align*}
    %Grafico aqui
    \begin{align*}
      P(K < X < 75)  = 0,3031\\
      =P(\frac{K-50}{10}< Z <2,5)= 0,3031
    \end{align*}
    %Grafico aqui
    \begin{align*}
      P(0 < Z < 2,5)  - P(0 < Z  < \frac{k-50}{k})=0,3031 \\
      0,49379 - 0,3031 = P(0 < Z < \frac{k-50}{10}) \\
      P(0<Z < \frac{\underbrace{k-50}_{0,495}}{10})= 0,19069  \\
      \frac{K-50}{10}= 0,495 \Rightarrow  K=4,95 +50 \\
      K=54,95
    \end{align*}
\end{enumerate}

    \end{description}
  \end{description}
  \subsubsection{Distribuição da Combinacao linear de v.a.\`s normais independentes}
  \begin{description}
    \item Sejam $X_1, X_2 , \ldots, X_n $ e  $n$ v.a.\`s tais que:
  \begin{align*}
    X_i \sim \mathtt{N}(\mu ; \sigma^2)  \quad \text{para} \quad i=1,2,\ldots,n
  \end{align*}
  Considere $Y= \sum_{i=1}^{n} X_i = X_1+\ldots+X_n$, temos que:
  \begin{align*}
    E(Y)  = E( \sum_{i}^{n} X_i ) = \sum_{i=1}^{n} E(X_i) \\
    = \sum_{i=1}^{n} \mu = n \times \mu
  \end{align*}
  Ou
  \begin{align*}
    E(Y )  =E( \sum_{i=1}^n X_i )= E(X_1 + \ldots +X_n) \\
    = E(X_1) +E(X_2) + \ldots +E(X_n)\\
    =\underbrace{\mu + \mu + \dots + \mu}_{n} = n \times \mu
  \end{align*}
  Assim:
  \begin{align*}
    Var(Y) = Var(\sum_{i=1}^{n} X_i)= \sum^{n}_{i=1} Var(X_i) \\
    = \sum_{i=1}^{n} \sigma^2 = n  \times \sigma^2
  \end{align*}
  Logo, $Y \sim \mathtt{N}(n\mu ; n \sigma^2)$.

  Pelas propriedades da distribuição normal, temos que se $Y\sim \mathtt{N}(n\mu; n\sigma^2)$, 
  a variável reduzida sera:
  \begin{align*}
    Z= \frac{Y- E(Y)}{\sqrt{Var(Y)}} = \frac{Y- n\mu}{\sqrt{n\sigma^2}} \sim \mathtt{N}(0,1)
  \end{align*}
  Analogamente, temos a média amostral:
  \begin{align*}
    \bar{X} = \frac{\sum_{i}^{n}}{X_i}
  \end{align*}
  Com isso, temos:
  \begin{align*}
    E(\bar{X}) = E( \frac{\sum_{i=1}^n X_i}{n} )= \frac{1}{n}\sum_{i=1}^{n} E(X_i) \\
    = \frac{1}{n} \sum_{i=1}^n \mu = \frac{1}{n} \times n \times \mu = \mu
  \end{align*}
  E também:
  \begin{align*}
    Var(\bar{X}) = Var(\frac{\sum_{i=1}^n}{n}) \\
    = \frac{1}{n^2} \sum_{i=1}^{n} Var(X_i) \\
    = \frac{1}{n^2} \sum_{i=1}^{n} \sigma^2 = \frac{1}{n^2} \times n \times \sigma^2 \\
    = \frac{\sigma^2}{n}
  \end{align*}
  Logo $\bar{X} \sim \mathtt{N} ( \mu ; \frac{\sigma^2}{n} ) $

  A variável reduzida eh:
  \begin{align*}
    Z = \frac{\bar{X}- E(\bar{X})}{\sqrt{Var(\bar{X})}} = \frac{\bar{x} - \mu}{\sqrt{\frac{\sigma^2}{n}}} \\
    = \frac{\bar{x}- \mu}{\frac{\sigma}{\sqrt{n}}} \\
    Z= \frac{\sqrt{n} (\bar{X} -\mu)}{\sigma} \sim \mathtt{N} (0,1)
  \end{align*}
\item {Exemplo:} O peso de sacos de parafusos empacotados por uma maquina tem media de $50g$ e desvio-padrão de $2g$.
  Assumindo que  o peso tem distribuição normal, qual a probabilidade de que 10 sacos pesem juntos de $490g$? 
  Qual a probabilidade de que a media desses 10 sacos sejam no maximo $52g$?

\begin{enumerate}[label=(\alph*)]
  \item
  \begin{align*}
    X \sim \mathtt{N} (50, 2^2) \\
    X_1, X_2, \ldots , X_{10 } \\
    Y= \sum_{i=1}^{n} X_i < 490 \\
    Y \sim \mathtt{N}(500 ; 10 \times 2^2) \\
    P(Y <490 ) = P(Z < \frac{490-500}{\sqrt{40}}) \\
    P(Z< -1,58) = 0,0571
  \end{align*}
  %grafico aqui

\item $\bar{X \leq 52g}$
  \begin{align*}
    \bar{X}  = \frac{\sum X_{i}}{n} \sim \mathtt{N}(\mu ; \frac{\sigma^2}{n}) \\
    \bar{X} \sim N(50; \frac{2^2}{10})
  \end{align*}
  \begin{align*}
    P(X \leq 52)  = P(Z \leq \frac{52-50}{\sqrt{\frac{2}{5}}}) \\
    = P(Z \leq 3,16)
  \end{align*}
  %Grafico 
  \begin{align*}
    P(Z \leq 3,16 ) = 0,9992
  \end{align*}
\end{enumerate}
\end{description}
\end{description}

